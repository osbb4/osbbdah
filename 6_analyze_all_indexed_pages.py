import sqlite3
import openai
from datetime import datetime, timezone
from config import OPENAI_API_KEY

openai.api_key = OPENAI_API_KEY
DB_PATH = "db/OSBBDAH.sqlite"

def analyze_page(title, text, source_url, published_at):
    prompt = f"""
–ù–∏–∂—á–µ –Ω–∞–≤–µ–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç –∑—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –ø—É–±–ª—ñ—á–Ω–æ–≥–æ –≤–µ–±—Å–∞–π—Ç—É, –ø—Ä–∏—Å–≤—è—á–µ–Ω–æ–≥–æ —Ç–µ–º–∞—Ç–∏—Ü—ñ –û–°–ë–ë:

–ù–∞–∑–≤–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∏: {title}
URL: {source_url}
–î–∞—Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó: {published_at if published_at else "–Ω–µ–≤—ñ–¥–æ–º–∞"}

{text}

–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü–µ–π –º–∞—Ç–µ—Ä—ñ–∞–ª —Ç–∞ —Å—Ñ–æ—Ä–º—É–ª—é–π:
1. –°—Ç–∏—Å–ª–∏–π –∑–º—ñ—Å—Ç –º–∞—Ç–µ—Ä—ñ–∞–ª—É (Summary)
2. –û—Å–Ω–æ–≤–Ω—É –ø—Ä–æ–±–ª–µ–º—É, –Ω–∞ —è–∫—É –≤—ñ–Ω —Å–ø—Ä—è–º–æ–≤–∞–Ω–∏–π (Problem)
3. –ü—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω—ñ —Ä—ñ—à–µ–Ω–Ω—è, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó —á–∏ –¥—ñ—ó (Solution)

–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
Summary: ...
Problem: ...
Solution: ...
"""

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢–∏ –∞–Ω–∞–ª—ñ—Ç–∏–∫, —â–æ —Å–ø–µ—Ü—ñ–∞–ª—ñ–∑—É—î—Ç—å—Å—è –Ω–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–º—É –∂–∏—Ç–ª–æ–≤–æ–º—É —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—ñ —Ç–∞ –û–°–ë–ë."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content.strip()

# –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏
conn = sqlite3.connect(DB_PATH)
cursor = conn.cursor()

# –î–æ–¥–∞—Ç–∏ –∫–æ–ª–æ–Ω–∫—É raw_gpt_response, —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î
cursor.execute("PRAGMA table_info(semantic_themes)")
columns = [row[1] for row in cursor.fetchall()]
if "raw_gpt_response" not in columns:
    cursor.execute("ALTER TABLE semantic_themes ADD COLUMN raw_gpt_response TEXT")
    conn.commit()

# –û—Ç—Ä–∏–º–∞—Ç–∏ –≤—Å—ñ –Ω–µ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –∞–±–æ –æ–Ω–æ–≤–ª–µ–Ω—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏
cursor.execute("""
SELECT url, site_id, title, raw_text, published_at
FROM indexed_pages
WHERE theme_id IS NULL OR last_analyzed_at IS NULL
ORDER BY published_at DESC NULLS LAST
""")
rows = cursor.fetchall()

if not rows:
    print("‚úÖ –£—Å—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ.")
    conn.close()
    exit()

for url, site_id, title, raw_text, published_at in rows:
    print(f"üîç –ê–Ω–∞–ª—ñ–∑: {url}")
    try:
        result = analyze_page(title, raw_text[:8000], url, published_at)
        raw = result.strip()
        summary = problem = solution = ""

        for line in raw.splitlines():
            if line.lower().startswith("summary:"):
                summary = line.split(":", 1)[1].strip()
            elif line.lower().startswith("problem:"):
                problem = line.split(":", 1)[1].strip()
            elif line.lower().startswith("solution:"):
                solution = line.split(":", 1)[1].strip()

        if not summary or not problem or not solution:
            print(f"‚ö†Ô∏è –ù–µ–≤–∞–ª—ñ–¥–Ω–∞ GPT-–≤—ñ–¥–ø–æ–≤—ñ–¥—å, –∑–±–µ—Ä–µ–∂–µ–Ω–æ –ª–∏—à–µ –¥–ª—è –∞—É–¥–∏—Ç—É.")
            continue

        now_utc = datetime.now(timezone.utc).isoformat()
        cursor.execute("""
            INSERT INTO semantic_themes (topic_id, title, summary, problem, solution, last_analyzed_at, source_type, source_url, raw_gpt_response)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (-1, title, summary, problem, solution, now_utc, "site", url, raw))

        cursor.execute("""
            UPDATE indexed_pages
            SET theme_id = ?, last_analyzed_at = ?
            WHERE url = ?
        """, (cursor.lastrowid, now_utc, url))

        conn.commit()
        print(f"‚úÖ OK: {url}")
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–ª—è {url}: {e}")

conn.close()
print("üèÅ –ê–Ω–∞–ª—ñ–∑ —É—Å—ñ—Ö —Å—Ç–æ—Ä—ñ–Ω–æ–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
