import sqlite3
import os
from openai import OpenAI
from dotenv import load_dotenv

# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∫–ª—é—á—ñ –∑ .env
load_dotenv()

# –°—Ç–≤–æ—Ä—é—î–º–æ –∫–ª—ñ—î–Ω—Ç–∞
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# === –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –±–∞–∑–∏ ===
conn = sqlite3.connect("db/OSBBDAH.sqlite")
cursor = conn.cursor()

# === –û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å, —è–∫—ñ —â–µ –Ω–µ –∞–Ω–∞–ª—ñ–∑—É–≤–∞–ª–∏—Å—å ===
cursor.execute("""
SELECT message_id, text
FROM messages
WHERE text IS NOT NULL AND LENGTH(text) > 20
AND message_id NOT IN (SELECT message_id FROM gpt_analysis_logs)
LIMIT 10
""")
messages = cursor.fetchall()

if not messages:
    print("‚ö†Ô∏è –ù–µ–º–∞—î –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É.")
    conn.close()
    exit()

# === –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç –º–æ–¥–µ–ª–µ–π ===
preferred_models = ["gpt-4o", "gpt-4.1", "gpt-3.5-turbo"]

available_models = [m.id for m in client.models.list().data]

selected_model = None
for model in preferred_models:
    if model in available_models:
        selected_model = model
        break

if not selected_model:
    print("‚ùå –ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø–Ω–æ—ó –º–æ–¥–µ–ª—ñ GPT —Å–µ—Ä–µ–¥ –±–∞–∂–∞–Ω–∏—Ö.")
    conn.close()
    exit()

print(f"‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –º–æ–¥–µ–ª—å: {selected_model}")

# === –ê–Ω–∞–ª—ñ–∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å GPT ===
for message_id, text in messages:
    prompt = f"""
{text}

–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ü–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∑ –≥—Ä—É–ø–∏ –û–°–ë–ë:

1. –ö–æ—Ä–æ—Ç–∫–æ –ø—ñ–¥—Å—É–º—É–π –∑–º—ñ—Å—Ç (Summary).
2. –í–∏–∑–Ω–∞—á –ø—Ä–æ–±–ª–µ–º—É, —è–∫–∞ –ø—ñ–¥–Ω—ñ–º–∞—î—Ç—å—Å—è (Problem).
3. –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –º–æ–∂–ª–∏–≤–µ —Ä—ñ—à–µ–Ω–Ω—è (Solution).

–§–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ:
Summary: ...
Problem: ...
Solution: ...
""".strip()

    try:
        response = client.chat.completions.create(
            model=selected_model,
            messages=[
                {"role": "system", "content": "–¢–∏ –µ–∫—Å–ø–µ—Ä—Ç –∑ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è –û–°–ë–ë –≤ –£–∫—Ä–∞—ó–Ω—ñ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        reply = response.choices[0].message.content.strip()

        # –ü–∞—Ä—Å–∏–Ω–≥ –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
        summary = problem = solution = ""
        for line in reply.splitlines():
            if line.lower().startswith("summary:"):
                summary = line.split(":", 1)[1].strip()
            elif line.lower().startswith("problem:"):
                problem = line.split(":", 1)[1].strip()
            elif line.lower().startswith("solution:"):
                solution = line.split(":", 1)[1].strip()

        if not summary:
            summary = reply  # fallback

        cursor.execute("""
            INSERT INTO gpt_analysis_logs (message_id, analysis_date, summary, problem_description, suggested_solution)
            VALUES (?, datetime('now'), ?, ?, ?)
        """, (message_id, summary, problem, solution))
        conn.commit()

        print(f"üß† –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è ID {message_id}")

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –¥–ª—è message_id {message_id}: {e}")
        continue

conn.close()
print("‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
